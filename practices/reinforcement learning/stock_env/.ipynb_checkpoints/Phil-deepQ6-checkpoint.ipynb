{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class DeepQNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    For a given observation, compute Q values for each action\n",
    "        Attributes\n",
    "    ----------\n",
    "    lr: float\n",
    "        learning rate\n",
    "    input_dims : list\n",
    "        [8]\n",
    "    fc1_dims : int\n",
    "        fully-connected layer 1\n",
    "    fc2_dims : int\n",
    "        fully-connected layer 2\n",
    "    n_actions : int\n",
    "        the number of actions\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, input_dims, fc1_dims, fc2_dims, n_actions, weight_decay=1e-5, p=0.0):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3 = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        self.dropout = nn.Dropout(p) \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.loss = nn.SmoothL1Loss() # Huber loss\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x) # dropout for regularization\n",
    "        actions = self.fc3(x)\n",
    "        \n",
    "        return actions\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, gamma, epsilon, lr, input_dims, batch_size, n_actions,\n",
    "                max_mem_size=100000, eps_end=0.01, eps_dec=1e-5, weight_decay=1e-5, p=0.0):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_min = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        self.lr = lr\n",
    "        self.action_space = [i for i in range(n_actions)] # list of actions\n",
    "        self.mem_size = max_mem_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mem_cntr = 0\n",
    "        \n",
    "        self.Q_eval = DeepQNetwork(self.lr, n_actions=n_actions, input_dims=input_dims, \n",
    "                                  fc1_dims=64, fc2_dims=64, weight_decay=weight_decay, p=p)\n",
    "        \n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims), dtype= np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "        \n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size # residual. The memory is finite, so we are reusing\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] =  action\n",
    "        self.terminal_memory[index] = done\n",
    "        \n",
    "        self.mem_cntr += 1\n",
    "        # reset self.mem_cntr to prevent possible overflow\n",
    "#        if self.mem_cntr >= self.mem_size:\n",
    "#            self.mem_cntr = 0\n",
    "        \n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            state = T.tensor([observation]).to(self.Q_eval.device) # [] is used because of the nn library. torch.Size([1, 6])\n",
    "            actions = self.Q_eval.forward(state)\n",
    "            action = T.argmax(actions).item() # .item() to get integer\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.mem_cntr < self.batch_size:\n",
    "            return\n",
    "\n",
    "        self.Q_eval.train()\n",
    "        self.Q_eval.optimizer.zero_grad()\n",
    "        \n",
    "        max_mem = min(self.mem_cntr, self.mem_size) \n",
    "        # select samples the number of self.batch_size out of max_mem \n",
    "        batch = np.random.choice(max_mem, self.batch_size, replace=False) # Don't select the same thing again\n",
    "        # array slicing [0,1,2,...,self.batch_size-1]\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32) \n",
    "        \n",
    "        state_batch = T.tensor(self.state_memory[batch]).to(self.Q_eval.device)\n",
    "        new_state_batch = T.tensor(self.new_state_memory[batch]).to(self.Q_eval.device)\n",
    "        reward_batch = T.tensor(self.reward_memory[batch]).to(self.Q_eval.device)\n",
    "        terminal_batch = T.tensor(self.terminal_memory[batch]).to(self.Q_eval.device)\n",
    "        \n",
    "        action_batch = self.action_memory[batch]\n",
    "        \n",
    "        q_eval = self.Q_eval.forward(state_batch)[batch_index, action_batch]\n",
    "        q_next = self.Q_eval.forward(new_state_batch)\n",
    "        q_next[terminal_batch] = 0.0\n",
    "                                                 \n",
    "        q_target = reward_batch + self.gamma * T.max(q_next, dim=1)[0]\n",
    "        \n",
    "        loss = self.Q_eval.loss(q_target, q_eval).to(self.Q_eval.device)\n",
    "        loss.backward()\n",
    "        T.nn.utils.clip_grad_norm_(self.Q_eval.parameters(), 0.5) # gradient clip\n",
    "        self.Q_eval.optimizer.step()\n",
    "        \n",
    "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon > self.eps_min else self.eps_min\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golde\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  200\n",
      "Size of Action Space ->  3\n",
      "episode  0 score -75.52 average score -75.52 epsilon 0.50  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  1 score -74.12 average score -74.82 epsilon 0.50  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  2 score -70.31 average score -73.32 epsilon 0.50  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  3 score -55.28 average score -68.81 epsilon 0.49  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  4 score -91.42 average score -73.33 epsilon 0.47  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  5 score -64.20 average score -71.81 epsilon 0.44  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  6 score -43.43 average score -67.75 epsilon 0.42  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  7 score -70.93 average score -68.15 epsilon 0.40  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  8 score -73.49 average score -68.74 epsilon 0.38  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  9 score -72.18 average score -69.09 epsilon 0.35  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  10 score -86.22 average score -70.65 epsilon 0.33  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  11 score -50.33 average score -68.95 epsilon 0.31  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  12 score -48.56 average score -67.38 epsilon 0.28  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  13 score -68.19 average score -67.44 epsilon 0.26  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  14 score -51.46 average score -66.38 epsilon 0.24  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  15 score -48.06 average score -65.23 epsilon 0.21  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  16 score -69.14 average score -65.46 epsilon 0.19  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  17 score -32.27 average score -63.62 epsilon 0.17  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  18 score -32.34 average score -61.97 epsilon 0.15  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  19 score 0.02 average score -58.87 epsilon 0.12  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  20 score -5.82 average score -56.35 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  21 score -28.68 average score -55.09 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  22 score 10.03 average score -52.26 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  23 score -37.72 average score -51.65 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  24 score -39.93 average score -51.18 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  25 score 12.39 average score -48.74 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  26 score 3.25 average score -46.81 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  27 score -36.35 average score -46.44 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  28 score 37.57 average score -43.54 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  29 score -5.27 average score -42.27 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  30 score 6.61 average score -40.69 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  31 score -16.67 average score -39.94 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  32 score -17.45 average score -39.26 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  33 score -14.95 average score -38.54 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  34 score 49.43 average score -36.03 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  35 score -41.94 average score -36.19 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  36 score 32.29 average score -34.34 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  37 score -11.22 average score -33.73 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  38 score -3.87 average score -32.97 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  39 score -3.20 average score -32.22 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  40 score -22.46 average score -31.99 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  41 score -1.42 average score -31.26 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  42 score 48.04 average score -29.41 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  43 score 113.11 average score -26.17 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  44 score -1.02 average score -25.62 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  45 score -30.26 average score -25.72 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  46 score -14.61 average score -25.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  47 score -23.37 average score -25.44 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  48 score -17.37 average score -25.27 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  49 score 30.92 average score -24.15 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  50 score 139.05 average score -20.95 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "saved best parameters\n",
      "episode  51 score 76.27 average score -19.08 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  52 score -2.86 average score -18.77 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  53 score 20.10 average score -18.05 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  54 score 6.29 average score -17.61 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  55 score 60.42 average score -16.22 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  56 score -36.47 average score -16.57 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  57 score 22.50 average score -15.90 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  58 score 27.66 average score -15.16 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  59 score -12.40 average score -15.11 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  60 score 11.50 average score -14.68 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  61 score 75.04 average score -13.23 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  62 score 1.13 average score -13.00 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  63 score 32.48 average score -12.29 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  64 score 63.43 average score -11.13 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  65 score -6.11 average score -11.05 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  66 score 21.85 average score -10.56 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  67 score 10.70 average score -10.25 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  68 score 8.65 average score -9.97 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  69 score 107.60 average score -8.29 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  70 score 71.41 average score -7.17 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  71 score 25.35 average score -6.72 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  72 score 93.26 average score -5.35 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  73 score 10.18 average score -5.14 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  74 score 8.38 average score -4.96 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  75 score 36.50 average score -4.41 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  76 score 51.73 average score -3.69 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  77 score 32.53 average score -3.22 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  78 score 15.84 average score -2.98 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  79 score 39.49 average score -2.45 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  80 score 68.63 average score -1.57 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  81 score 110.85 average score -0.20 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  82 score 56.24 average score 0.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  83 score 11.60 average score 0.61 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  84 score 111.14 average score 1.91 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  85 score 27.59 average score 2.21 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  86 score 105.67 average score 3.40 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  87 score 284.43 average score 6.59 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  88 score 81.06 average score 7.43 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  89 score 208.59 average score 9.67 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  90 score 24.16 average score 9.82 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  91 score 183.70 average score 11.71 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  92 score -9.91 average score 11.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  93 score 42.34 average score 11.81 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  94 score 61.29 average score 12.33 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  95 score 46.59 average score 12.69 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  96 score 51.79 average score 13.09 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  97 score 63.24 average score 13.60 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  98 score 13.39 average score 13.60 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  99 score 84.36 average score 14.31 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  100 score 62.01 average score 15.68 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  101 score 41.86 average score 16.84 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  102 score 11.23 average score 17.66 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  103 score 5.26 average score 18.26 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  104 score 53.54 average score 19.71 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  105 score 85.66 average score 21.21 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  106 score 99.65 average score 22.64 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  107 score -11.89 average score 23.23 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  108 score 25.02 average score 24.22 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  109 score 53.53 average score 25.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  110 score 46.47 average score 26.80 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  111 score -7.79 average score 27.23 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  112 score 186.47 average score 29.58 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  113 score 95.17 average score 31.21 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  114 score 38.35 average score 32.11 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  115 score 39.60 average score 32.99 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  116 score 90.21 average score 34.58 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  117 score 224.43 average score 37.15 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  118 score 106.90 average score 38.54 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  119 score -21.77 average score 38.32 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  120 score 110.09 average score 39.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  121 score 44.33 average score 40.21 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  122 score 40.46 average score 40.52 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  123 score 32.44 average score 41.22 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  124 score 77.13 average score 42.39 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  125 score 65.63 average score 42.92 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  126 score 99.73 average score 43.88 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  127 score 149.99 average score 45.75 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  128 score 30.69 average score 45.68 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  129 score 35.64 average score 46.09 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  130 score 177.28 average score 47.80 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  131 score 52.04 average score 48.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  132 score -1.64 average score 48.64 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  133 score 19.28 average score 48.98 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  134 score 81.69 average score 49.31 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  135 score 61.31 average score 50.34 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  136 score 167.36 average score 51.69 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  137 score 23.34 average score 52.03 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  138 score 145.95 average score 53.53 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  139 score 107.61 average score 54.64 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  140 score 64.75 average score 55.51 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  141 score 134.35 average score 56.87 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  142 score 49.06 average score 56.88 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  143 score 37.52 average score 56.12 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  144 score 120.62 average score 57.34 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  145 score 57.77 average score 58.22 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  146 score 233.95 average score 60.71 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  147 score 130.56 average score 62.25 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  148 score 104.89 average score 63.47 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  149 score 47.46 average score 63.63 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  150 score 39.38 average score 62.64 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  151 score 146.33 average score 63.34 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  152 score 71.17 average score 64.08 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  153 score 20.30 average score 64.08 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  154 score 77.86 average score 64.80 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  155 score 175.37 average score 65.95 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  156 score 185.50 average score 68.17 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  157 score 54.31 average score 68.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  158 score 64.73 average score 68.85 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  159 score 76.85 average score 69.75 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  160 score -13.09 average score 69.50 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  161 score 118.01 average score 69.93 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  162 score 58.09 average score 70.50 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  163 score 306.51 average score 73.24 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved best parameters\n",
      "episode  164 score 162.22 average score 74.23 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  165 score 115.61 average score 75.45 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  166 score 68.52 average score 75.91 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  167 score 142.15 average score 77.23 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  168 score 137.37 average score 78.51 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  169 score 47.80 average score 77.92 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  170 score 97.12 average score 78.17 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  171 score 140.98 average score 79.33 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  172 score 146.73 average score 79.86 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  173 score 126.61 average score 81.03 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  174 score 163.21 average score 82.58 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  175 score 186.04 average score 84.07 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  176 score 81.22 average score 84.37 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  177 score 60.66 average score 84.65 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  178 score 98.89 average score 85.48 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  179 score 48.55 average score 85.57 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  180 score 140.21 average score 86.28 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  181 score 160.81 average score 86.78 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  182 score 156.89 average score 87.79 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  183 score 99.46 average score 88.67 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  184 score 111.15 average score 88.67 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  185 score 41.93 average score 88.81 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  186 score 56.86 average score 88.32 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  187 score 13.81 average score 85.62 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  188 score 84.91 average score 85.66 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  189 score 214.01 average score 85.71 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  190 score 96.09 average score 86.43 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  191 score 83.92 average score 85.43 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  192 score 25.74 average score 85.79 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  193 score 115.12 average score 86.52 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  194 score 177.42 average score 87.68 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  195 score 88.06 average score 88.09 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  196 score 215.39 average score 89.73 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  197 score -33.66 average score 88.76 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  198 score 188.79 average score 90.51 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  199 score 151.68 average score 91.19 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  200 score 131.45 average score 91.88 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  201 score 111.74 average score 92.58 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  202 score 113.30 average score 93.60 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  203 score 66.87 average score 94.22 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  204 score 93.26 average score 94.61 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  205 score 0.12 average score 93.76 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  206 score -25.87 average score 92.50 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  207 score 135.67 average score 93.98 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  208 score 123.10 average score 94.96 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  209 score 115.89 average score 95.58 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  210 score 60.64 average score 95.73 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "saved check point\n",
      "episode  211 score 134.01 average score 97.14 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  212 score 92.71 average score 96.21 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  213 score 94.36 average score 96.20 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  214 score 122.37 average score 97.04 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  215 score 71.89 average score 97.36 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  216 score 136.47 average score 97.82 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n",
      "episode  217 score 25.01 average score 95.83 epsilon 0.10  profit_iteration 0.00  iterations 2298.00  long_return 1.39 \n"
     ]
    }
   ],
   "source": [
    "#from env import TradingSPYEnv\n",
    "#from env2 import TradingSPYEnv\n",
    "from env6 import TradingSPYEnv\n",
    "import numpy as np\n",
    "import os\n",
    "state_dict_path = os.path.join(os.getcwd(),'test6.pth')\n",
    "best_state_dict_path = os.path.join(os.getcwd(),'best6.pth')\n",
    "env = TradingSPYEnv(init_invest=100.0, sma_len=[5,10,15,20,25],train_test_split=0.5)\n",
    "#num_states = len(env.reset())\n",
    "num_states = env.reset(50).shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.n\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "agent = Agent(gamma=0.99, epsilon=0.5, batch_size=8192, n_actions=num_actions, eps_dec=1e-5, eps_end=0.1, \n",
    "              input_dims = [num_states], lr=0.00005, p=0.5,\n",
    "              weight_decay=1e-5)\n",
    "#agent.Q_eval.load_state_dict(T.load(state_dict_path))\n",
    "agent.Q_eval.load_state_dict(T.load(best_state_dict_path))\n",
    "scores, eps_history = [], []\n",
    "n_games = 1000\n",
    "max_score = 0.0\n",
    "#learn_frequency = 4\n",
    "#learn_count = 0\n",
    "\n",
    "\n",
    "for i in range(n_games):\n",
    "    score = 0.0\n",
    "    done = False\n",
    "    observation = env.reset(50)\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        if (observation_ is not None): \n",
    "            score += reward\n",
    "            agent.store_transition(observation, action, reward, observation_, done)\n",
    "        agent.learn()\n",
    "#        if learn_count == learn_frequency:\n",
    "#            agent.learn()\n",
    "#            learn_count = 0\n",
    "#        else:\n",
    "#            learn_count += 1\n",
    "        observation = observation_\n",
    "#    agent.learn() # Learn after one episode\n",
    "    scores.append(score)\n",
    "    eps_history.append(agent.epsilon)\n",
    "    \n",
    "    avg_score = np.mean(scores[-100:])\n",
    "    \n",
    "    print('episode ', i, 'score %.2f' % score,\n",
    "         'average score %.2f' % avg_score,\n",
    "         'epsilon %.2f ' % agent.epsilon,\n",
    "         'profit_iteration %.2f ' % info['profit_iteration'],\n",
    "         'iterations %.2f ' % info['iterations'],\n",
    "         'long_return %.2f ' % info['long_return']\n",
    "         )\n",
    "    \n",
    "    if i !=0:        \n",
    "        if (i % 10 == 0):\n",
    "            T.save(agent.Q_eval.state_dict(), state_dict_path)\n",
    "            print(\"saved check point\")\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            T.save(agent.Q_eval.state_dict(), best_state_dict_path)\n",
    "            print(\"saved best parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "state_dict_path = os.path.join(os.getcwd(),'test6.pth')\n",
    "T.save(agent.Q_eval.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_learning_curve\n",
    "x = [i+1 for i in range(n_games)]\n",
    "filename = 'stock_env6.png'\n",
    "plot_learning_curve(x, scores, eps_history, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(np.arange(len(agent.action_memory)),agent.action_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.Q_eval.load_state_dict(T.load(state_dict_path)) # load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.state_memory[-4:],\n",
    "        agent.new_state_memory[-4:], \n",
    "        agent.action_memory[-4:], \n",
    "        agent.reward_memory[-4:], \n",
    "        agent.terminal_memory[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = agent.action_memory[-500:]\n",
    "print('mean', np.mean(tmp))\n",
    "print('max', np.max(tmp))\n",
    "print('min', np.min(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
